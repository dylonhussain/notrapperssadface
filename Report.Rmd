---
title: "Pulsars"
author: "Dylon Hussain"
date: "5/3/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Introduction
Here we describe an analysis to identify pulsars from metrics from their signal. Pulsars are difficult to identify because they have a periodic signal but often stars that are not pulsars have periodic signals because of noise. Considering the large amount of stars observed and the scarcity of pulsars, there is great interest in utilizing machine learning to identifying pulsars. Here we examine the suitability of multiple popular machine learning algorithms for this task. Hereafter we will refer to observations that were determined to be pulsars as '1' and others as '0'.  

```{r loading-libs, message=FALSE, echo = FALSE}
library(ggplot2)
library(tidyverse)
library(knitr)
train = read_rds('train.rda')
```

## Methods
The dataset used for this analysis contains 17,898 observations; 1639 of which are known to have come from pulsars and the remaining observations did not, but have similar qualities due to noise. The dataset was split into a train set to train the model and a test set to test it's performance. A 70:30 split was chosen for this analysis because it results in an adequate number of pulsars to train the model, more than 1000. This split will also retain a sufficient number of pulsars for an accurate estimate of it's performance in future applications, where as a 90:10 split would have resulted in less than 200 pulsars and not provided an accurate estimate. The test data contains 8 predictors, listed in Table 1, which are funtionals on the observed signals that the stars emitted. In consideration of the computational cost of running this algorithm, visual methods were used to ascertain which variables were strongly related and could be discarded without significantly detrimenting the performance of the model.
```{r Predictors, echo = FALSE}
  Predictors = c('Mean of the integrated profile.', 'Standard deviation of the integrated profile.',
           'Excess kurtosis of the integrated profile.', 'Skewness of the integrated profile.',
           'Mean of the DM-SNR curve.', 'Standard deviation of the DM-SNR curve.',
           'Excess kurtosis of the DM-SNR curve.','Skewness of the DM-SNR curve.')
  Predictors_names = c('pmean', 'psd', 'pkurt', 'pskew', 'cmean', 'csd', 'ckurt', 'cskew')
  varstable = data.frame(Predictors, Predictors_names)
  kable(varstable, caption = 'Table 1')
  
```

## Analysis

### Predictor Selection

```{r Boxplots, echo = FALSE, }
  train = readRDS('train.Rda')
  train %>% gather('key', 'value', 1:8) %>%  
    ggplot(aes(x = pulsar, y = value, group = pulsar)) + 
    geom_boxplot(outlier.size = .1)  + stat_boxplot(geom = 'errorbar', width = .5)+
    facet_wrap(~key, scales = 'free')+
    ggtitle('Figure 1')
```
Boxplots were generated for each of the predictors and are shown in Figure 1. Csd was the first predictor that was chosen to train the algorithm because, as shown above, $Q_2$ of 1 is greater than $Q_4$ of 0. The data was then examined to determine which predictors were strongly related to csd and thus, could be excluded from the training set. Each of the predictors were plotted against csd in Figure 2, cskew and ckurt were both identified as predictors that appeared to be functions of csd and were removed. 

```{r Corr1, echo = FALSE, }
  train[,names(train) != 'pulsar'] %>% 
    gather('key', 'value', -one_of('csd')) %>% 
    ggplot(aes(x = csd, y = value, group = key)) + 
    geom_point(size = .1) + facet_wrap(~key, scales = 'free')+
    ggtitle('Figure 2')
```
Pkurt was then selected to remain in the training set because it also has the property that $Q_2$ of 1 is greater than $Q_4$ of 0. Each remaining predictor was then plotted against pkurt, in Figure 3, to identify those that had a strong relation to pkurt. Pmean and pskew appeared to be strongly related to pkurt so they were removed from the training set. 
```{r Corr1, echo = FALSE, }
  train[,!(names(train) %in% c('pulsar', 'ckurt', 'cskew', 'csd'))] %>% 
    gather('key', 'value', -one_of('pkurt')) %>% 
    ggplot(aes(x = pkurt, y = value, group = key)) + 
    geom_point(size = .1) + facet_wrap(~key, scales = 'free')+
    ggtitle('Figure 3')
```

  

Finally, the remaining two variables, cmean and psd, were plotted against each other. As shown in Figure 4 they are not related so they were both retained in the final training set, summarized in Table 2 below. 

```{r Corr3, echo = FALSE, }
  train[,c('cmean', 'psd')]%>% ggplot(aes(x = cmean, y = psd)) + geom_point(size = .1) +
    ggtitle('Figure 4')
```
I determined that the variables to train the algorithm with were listed in table 2
```{r Final Predictors, echo = FALSE}
  Predictors_final = c( 'Standard deviation of the integrated profile.',
           'Excess kurtosis of the integrated profile.',
           'Mean of the DM-SNR curve.', 'Standard deviation of the DM-SNR curve.')
  Predictors_names_final = c('psd', 'pkurt','cmean', 'csd')
  varstable = data.frame(Predictors_final, Predictors_names_final)
  kable(varstable, caption = 'Table 2')
  
```

###Algorithm Selection START HERE!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
4 popular machine learning algorithms were trained with the test data and with different metrics. The metrics that were used were accuracy (default), F1 score (with beta ) and assessed for their suitability for the task table 3 shows their performance metrics. 
```{r Performance, echo = FALSE}
  allstats = readRDS('allstats.Rda') %>% arrange(desc(sensitivity)) %>% arrange(desc(specificity))
  kable(allstats, caption = 'Model Performance', digits = 4)
  
```
Since specificity is the most important metric because stars that are the algorithm predicts are pulsars will be further investigated and ones rejected may not be investigated to overturn the decision. for this reason the rborist model trained with a beta=.8 was chosen because it has the highest specificity without sacrificing sensitivity. 

## Results
```{r Specificity, echo = FALSE}
 ans = readRDS('ans.Rda')
```
Using the random forest model trained with Beta=.8 a specificity of `r  round(ans$byClass[['Specificity']], digits = 4)` was achieved


## Conclusion

###not sure if use
at low ckurt the relation wasn't one to one but this feature appears in pulsars and not-pulsars so it was determined that this is still a good choice to exclude.
```{R ckurt_exclusion, echo = FALSE}
  train %>% group_by(pulsar) %>%
    ggplot(aes(x = csd, y = ckurt, group = pulsar)) + 
    geom_point(size = .1) + facet_wrap(~pulsar)
```
